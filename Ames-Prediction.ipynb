{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The Ames Housing dataset contains information from the Ames Assessor’s Office used in computing assessed values for individual \n",
    "residential properties sold in Ames, IA, USA from 2006 to 2010. This data set was constructed for the purpose of an end of \n",
    "semester project for an undergraduate regression course. The original data (obtained directly from the Ames Assessor’s Office)\n",
    "is used for tax assessment purposes but lends itself directly to the prediction of home selling prices.\n",
    "\n",
    "As a prospective buyer of a property in Ames, I would like to find out how much should i expect to pay for a property, given its house characteristics (i.e. quality), features (i.e. facilities), and embellishments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Executive Summary\n",
    "\n",
    "A series of data cleaning, exploratory data analysis, feature engineering and modelling are carried out on the dataset. A Linear Regression model with Ridge correction was established, which brought me to within a root mean squared error of 26,210 (on Kaggle), with a R-Squared score of 0.89. It suggests that selected features contained within the dataset are good (but not exhaustive) indicators of the true market value price of a property, with certain accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "from sklearn import linear_model #to build the model\n",
    "from sklearn.metrics import mean_squared_error #to evaluate the model\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNet, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, cross_val_predict\n",
    "import pandas_profiling\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/train.csv')\n",
    "test = pd.read_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observation for first 10 rows of data\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing spaces in column names\n",
    "train.columns = train.columns.map(lambda column: column.replace(' ',''))\n",
    "test.columns = test.columns.map(lambda column: column.replace(' ',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tool for detailed univariate analysis. Do note that the report will take some time to load.\n",
    "train.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Removal of anomalies in independent numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot function to further explore standout features from report\n",
    "def scatter(feature):\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    ax = plt.gca()\n",
    "    x = train[feature]\n",
    "    y = train.SalePrice\n",
    "    plt.title('Scatter Plot',fontsize=16,fontweight='bold')\n",
    "    plt.xlabel(feature,fontsize=16)\n",
    "    plt.ylabel('Sales Price',fontsize=16)\n",
    "\n",
    "    ax.scatter(x, y, c='k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually check for presence of anomalies in Lot Area\n",
    "scatter('LotArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop anomalies where lot area >70,000 - left 2048 observations\n",
    "train.drop(train[train['LotArea']>70000].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually check for presence of anomalies in Total Bsmt \n",
    "scatter('TotalBsmtSF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop anomalies where total bsmt sf > 4,000- left 2046 observations\n",
    "train.drop(train[train['TotalBsmtSF']>4000].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually check for presence of anomalies in Garage Yr Blt\n",
    "scatter('GarageYrBlt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing value of anomaly in GarageYrBlt, with the assumption that its a wrong entry, to a reasonable correction.\n",
    "train.at[1699,'GarageYrBlt'] = 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing anomaly in LotArea feature in test\n",
    "test.at[214,'LotArea'] = test['LotArea'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature engineering for independent variables\n",
    "\n",
    "1. To clean null values using suitable replacement e.g. To fill null values with 'NA' where it is an option\n",
    "2. Convert remaining categorical features to numerical equivalent, using reasonable \"quality\" based scale, and dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barchart representing % of column with missing data\n",
    "train_na = (train.isnull().sum() / len(train)) * 100\n",
    "train_na = train_na.drop(train_na[train_na == 0].index).sort_values()\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.xlabel('% of null values',fontsize=16)\n",
    "plt.ylabel('Features',fontsize=16)\n",
    "plt.title('Null Values per Column',fontsize=16,fontweight='bold')\n",
    "train_na.plot(kind='barh',fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.A. Cleaning of initial null values\n",
    "\n",
    "Cleaning of both categorical and numerical columns, with the exception of those that will be cleaned in section 4.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for filling NaNs\n",
    "def clean_check_col(df, col,fill_value):\n",
    "    df[col] = df[col].fillna(fill_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaNs with 'NA', where it is already an option\n",
    "for i in ['MiscFeature','Alley','Fence','GarageType','BsmtFinType2','BsmtFinType1']:\n",
    "    clean_check_col(train, i,'NA')\n",
    "    clean_check_col(test, i,'NA')\n",
    "    \n",
    "#fill NaNs with 'None', where it is already an option\n",
    "for i in ['MasVnrType']:\n",
    "    clean_check_col(train, i,'None')\n",
    "    clean_check_col(test, i,'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaNs with mode for discrete variables\n",
    "for i in ['GarageYrBlt','BsmtHalfBath','BsmtFullBath','GarageCars']:\n",
    "    clean_check_col(train, i,int(train[i].mode()))\n",
    "    clean_check_col(test, i,int(train[i].mode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaNs with mean for continuous variables\n",
    "for i in ['MasVnrArea','GarageArea','TotalBsmtSF','BsmtUnfSF','BsmtFinSF2','BsmtFinSF1']:\n",
    "    clean_check_col(train, i,float(train[i].mean()))\n",
    "    clean_check_col(test, i,float(train[i].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaNs with 0 for Lot Frontage\n",
    "for i in ['LotFrontage']:\n",
    "    clean_check_col(train, i,0)\n",
    "    clean_check_col(test, i,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.B. Converting categorical variables\n",
    "\n",
    "1. To modify quality-based columns into a range of integers with information about their relative \"goodness\"\n",
    "2. To modify remaining categorical variables to reasonable integer based columns e.g. dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to turn \"quality\" columns into numeric ones, to be applied in next few cells.\n",
    "def clean_quality_col(df, col, dict_values,fill_value):\n",
    "    clean_check_col(df, col,fill_value)\n",
    "    \n",
    "    for key,value in dict_values.items():\n",
    "        df[col] = df[col].map(lambda cell: cell.replace(key,str(value)))\n",
    "    df[col] = df[col].astype(int) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_cols = ['ExterQual','ExterCond','KitchenQual','BsmtQual','HeatingQC','FireplaceQu',\n",
    "                'GarageQual','GarageCond','BsmtCond','PoolQC']\n",
    "dict_values = {'Ex': 5,\n",
    "               'Gd' : 4,\n",
    "               'TA' : 3,\n",
    "               'Fa' : 2, \n",
    "               'Po' : 1,\n",
    "               'NA' : 0 }\n",
    "for col in quality_cols:\n",
    "    clean_quality_col(train, col, dict_values, \"NA\")\n",
    "    clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'LandSlope'\n",
    "dict_values = {'Gtl' : 3,\n",
    "               'Mod' : 2,\n",
    "               'Sev' : 1,\n",
    "               'NA'  : 0 }\n",
    "clean_quality_col(train, col, dict_values, \"NA\")\n",
    "clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'BsmtExposure'\n",
    "dict_values = {'Gd' : 4,\n",
    "               'Av' : 3,\n",
    "               'Mn' : 2,\n",
    "               'No' : 1,\n",
    "               'NA' : 0 }\n",
    "clean_quality_col(train, col, dict_values, \"NA\")\n",
    "clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'GarageFinish'\n",
    "dict_values = {'Fin' : 3, \n",
    "               'RFn' : 2,  \n",
    "               'Unf' : 1,\n",
    "               'NA' : 0 }\n",
    "clean_quality_col(train, col, dict_values, \"NA\")\n",
    "clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'CentralAir'\n",
    "dict_values = {'Y' : 1, \n",
    "               'N' : 0 }\n",
    "clean_quality_col(train, col, dict_values, \"N\")\n",
    "clean_quality_col(test, col, dict_values, \"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Fence'\n",
    "dict_values = {'GdPrv' : 4,\n",
    "               'MnPrv' : 3,\n",
    "               'GdWo' : 2,\n",
    "               'MnWw'  : 1,\n",
    "               'NA' : 0}\n",
    "clean_quality_col(train, col, dict_values, \"NA\")\n",
    "clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_cols = ['BsmtFinType1','BsmtFinType2']\n",
    "dict_values = {'GLQ': 6,\n",
    "               'ALQ' : 5,\n",
    "               'BLQ' : 4,\n",
    "               'Rec' : 3, \n",
    "               'LwQ' : 2,\n",
    "               'Unf' : 1,\n",
    "               'NA' : 0}\n",
    "for col in quality_cols:\n",
    "    clean_quality_col(train, col, dict_values, \"NA\")\n",
    "    clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'LotShape'\n",
    "dict_values = {'Reg' : 4,\n",
    "               'IR1' : 3,\n",
    "               'IR2' : 2,\n",
    "               'IR3' : 1 }\n",
    "clean_quality_col(train, col, dict_values, \"NA\")\n",
    "clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Utilities'\n",
    "dict_values = {'AllPub' : 4,\n",
    "               'NoSewr' : 3,\n",
    "               'NoSeWa' : 2,\n",
    "               'ELO'  : 1 }\n",
    "clean_quality_col(train, col, dict_values, \"NA\")\n",
    "clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Electrical'\n",
    "dict_values = {'SBrkr' : 5,\n",
    "               'FuseA' : 4,\n",
    "               'FuseF' : 3,\n",
    "               'FuseP' : 2,\n",
    "               'Mix'  : 1 }\n",
    "clean_quality_col(train, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Functional'\n",
    "dict_values = {'Typ' : 8,\n",
    "               'Min1' : 7,\n",
    "               'Min2' : 6,\n",
    "               'Mod' : 5,\n",
    "               'Maj1' : 4,\n",
    "               'Maj2' : 3,\n",
    "               'Sev' : 2,\n",
    "               'Sal'  : 1 }\n",
    "clean_quality_col(train, col, dict_values, \"NA\")\n",
    "clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'PavedDrive'\n",
    "dict_values = {'Y' : 3,\n",
    "               'P' : 2,\n",
    "               'N' : 1,}\n",
    "clean_quality_col(train, col, dict_values, \"NA\")\n",
    "clean_quality_col(test, col, dict_values, \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns left that are categorical, to be transformed using dummy variables, in section 6.\n",
    "obj_cols = train.select_dtypes([np.object]).columns\n",
    "obj_cols2 = test.select_dtypes([np.object]).columns\n",
    "print('Categorical features in train to be converted using dummy variables include: ', '\\n', list(obj_cols))\n",
    "print('\\n')\n",
    "print('Categorical features in test to be converted using dummy variables include: ', '\\n',list(obj_cols2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Observation for dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#understanding the statistics of our dependent variable\n",
    "train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Density Plot\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.ylabel('Frequency',fontsize=16)\n",
    "plt.xlabel('SalePrice',fontsize=16)\n",
    "sns.distplot(train.SalePrice,fit=norm);\n",
    "plt.title('SalePrice distribution',fontsize=16,fontweight='bold');\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(train['SalePrice']);\n",
    "# QQ-plot\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.ylabel('Ordered Values',fontsize=16)\n",
    "plt.xlabel('Theoretical Qualities',fontsize=16)\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graphs suggest that Sales Price is right skewed, and has peakedness. Since linear regression models fits better on normally distributed data, and performs more \"well-behaved\", we should normalize the target variable by taking log(feature+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transform the target:\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Density Plot\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.ylabel('Frequency',fontsize=16)\n",
    "plt.xlabel('SalePrice',fontsize=16)\n",
    "sns.distplot(train.SalePrice,fit=norm);\n",
    "plt.title('SalePrice distribution',fontsize=16,fontweight='bold');\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(train['SalePrice']);\n",
    "# QQ-plot\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.ylabel('Ordered Values',fontsize=16)\n",
    "plt.xlabel('Theoretical Qualities',fontsize=16)\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dependent variable (Sale Price) appears more normally distributed. However, there appears to be extreme outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.title('SalePrice Boxplot',fontsize=16,fontweight='bold');\n",
    "plt.xlabel('SalePrice',fontsize=16)\n",
    "sns.boxplot(train['SalePrice']);\n",
    "#Boxplot suggests that there are extreme outliers in the transformed target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of 2 anomalies in price where deviation is >5 sigma - 2044 observations left\n",
    "train.drop(train[train['SalePrice']<10].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding top 20 strongly correlated features with Sale Price, ordered by descending order\n",
    "corrmat = train.corr()\n",
    "columns = abs(corrmat['SalePrice']).sort_values(ascending=False).head(20)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Finding top strongly correlated features with OverallQual\n",
    "columns2 = abs(corrmat['OverallQual']).sort_values(ascending=False).head(20)\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than sales price, unsurprisingly, Externalqual, KitchenQual and BsmtQual are also strongly correlated with OverallQual, as the 3 features are complementary. It is important to consider whether we will need to drop these features later to minimize multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation heatmap of top 20 strongly correlated features with SalesPrice\n",
    "plt.figure(figsize=(9,6))\n",
    "sns.heatmap(pd.DataFrame(columns.head(20)),annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot to observe top 10 features that have strongest correlation with sales price\n",
    "sns.pairplot(train, vars = columns.head(10).index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subplot to investigate deeper into top few eatures, and its relation with Salesprice\n",
    "fig, axes = plt.subplots(3, 2,figsize=(16,16))\n",
    "\n",
    "#Boxplot between OverallQual and SalesPrice\n",
    "var = 'OverallQual'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "axes[0][0].set_ylabel('SalePrice')\n",
    "axes[0][0].set_xlabel('OverallQual')\n",
    "axes[0][0].set_title('SalePrice vs OverallQual Boxplot',fontweight='bold',size=14)\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\",ax=axes[0][0], data=data)\n",
    "\n",
    "#Scatterplot between GrLivArea and SalesPrice\n",
    "var = 'GrLivArea'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "axes[0][1].set_ylabel('GrLivArea')\n",
    "axes[0][1].set_xlabel('SalePrice')\n",
    "axes[0][1].set_title('GrLivArea vs SalePrice Scatterplot',fontweight='bold',size=14)\n",
    "scat = sns.regplot(x=\"SalePrice\", y=var, ax=axes[0][1], data=train,  scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"});\n",
    "\n",
    "#Scatterplot between GarageArea and SalesPrice\n",
    "var = 'GarageArea'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "axes[1][0].set_ylabel('GarageArea')\n",
    "axes[1][0].set_xlabel('SalePrice')\n",
    "axes[1][0].set_title('GarageArea vs SalePrice Scatterplot',fontweight='bold',size=14)\n",
    "scat = sns.regplot(x=\"SalePrice\", y=var, ax=axes[1][0], data=train,  scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"});\n",
    "\n",
    "#Scatterplot between TotalBsmtSF and SalesPrice\n",
    "var = 'TotalBsmtSF'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "axes[1][1].set_ylabel('TotalBsmtSF')\n",
    "axes[1][1].set_xlabel('SalePrice')\n",
    "axes[1][1].set_title('TotalBsmtSF vs SalePrice Scatterplot',fontweight='bold',size=14)\n",
    "scat = sns.regplot(x=\"SalePrice\", y=var, ax=axes[1][1], data=train,  scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"});\n",
    "\n",
    "#Scatterplot between 1stFlrSF and SalesPrice\n",
    "var = '1stFlrSF'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "axes[2][0].set_ylabel('1stFlrSF')\n",
    "axes[2][0].set_xlabel('SalePrice')\n",
    "axes[2][0].set_title('1stFlrSF vs SalePrice Scatterplot',fontweight='bold',size=14)\n",
    "scat = sns.regplot(x=\"SalePrice\", y=var, ax=axes[2][0], data=train,  scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"});\n",
    "\n",
    "#Boxplot between GarageFinish and SalesPrice\n",
    "var = 'GarageFinish'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "axes[2][1].set_ylabel('SalePrice')\n",
    "axes[2][1].set_xlabel('GarageFinish')\n",
    "axes[2][1].set_title('GarageFinish vs OverallQual Boxplot',fontweight='bold',size=14)\n",
    "axes[2][1].set_ylim([10, 14]) \n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\",ax=axes[2][1], data=data)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is strong apparent correlation between the selected features and sales price, seen especially in the scatterplots with small confidence intervals for the plotted line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modelling using Logistic Regression, LassoCV, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the top 20 correlated features that will be used for regression, in a modified variable\n",
    "# A training model was established using the train.csv, with the test.csv as the variables to predict upon.\n",
    "train_x = train[[x for x in columns.index if x != 'SalePrice']]\n",
    "test_x = test[[x for x in columns.index if x != 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting selected features with categorical values into dummy\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiating, fitting and transforming using polynomial features\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "\n",
    "train_x = poly.fit_transform(train_x)\n",
    "test_x = poly.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_x.shape)\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiating, fitting and transforming standard scaler\n",
    "ss = StandardScaler()\n",
    "train_x = ss.fit_transform(train_x)\n",
    "test_x = ss.transform(test_x)\n",
    "\n",
    "train_y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiating linear regerssion, lasso and ridge, and cross-validated to find model with best fit.\n",
    "lr = LinearRegression()\n",
    "lasso = LassoCV(n_alphas=20)\n",
    "ridge = RidgeCV(alphas=np.linspace(.1, 10, 200))\n",
    "\n",
    "lr_scores = cross_val_score(lr, train_x, train_y, cv=3)\n",
    "print('Linear Regression Rsquared score is {}'.format(lr_scores.mean()))\n",
    "\n",
    "lasso_scores = cross_val_score(lasso, train_x, train_y, cv=3)\n",
    "print('Lasso Regression Rsquared score is {}'.format(lasso_scores.mean()))\n",
    "\n",
    "ridge_scores = cross_val_score(ridge, train_x, train_y, cv=3)\n",
    "print('Ridge Regression Rsquared score is {}'.format(ridge_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression appears to perform best amongst the 3 models. For our prediction, we'll be using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establishing a Ridge model, with its score\n",
    "ridge.fit(train_x, train_y)\n",
    "print('The model\\'s score is {}'.format(ridge.score(train_x, train_y)))\n",
    "\n",
    "#Creating a prediction using Lasso, storing it into the pred variable\n",
    "pred = np.expm1(ridge.predict(test_x))\n",
    "pred\n",
    "\n",
    "#Visualisation of coefficients (with polynomnial)\n",
    "pd.Series(ridge.coef_, index=[poly.get_feature_names(columns.index)]).plot.bar(figsize=(15, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. For submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_df(predict):\n",
    "    df = pd.DataFrame(test['Id'])\n",
    "    df['SalePrice'] = predict\n",
    "    df.set_index(['Id'], inplace = True)\n",
    "    df.to_csv('answer.csv')\n",
    "    print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df(pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final submission score on Kaggle:\n",
    "\n",
    "#### Public Score: 26,210\n",
    "#### Private Score: 32,936"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
